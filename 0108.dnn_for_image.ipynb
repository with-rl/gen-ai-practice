{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import requests\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "from datasets import load_dataset, VerificationMode\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient False\n",
    "# Pytorch에서 동작을 확안하기 위해서 Gradient 계산을 하지 않도록 설정\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MNIST fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear = nn.Linear(28*28, 10)  # 28*28 입력, 10 출력 (클래스 수)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "model = LinearModel()\n",
    "model.to(device)\n",
    "\n",
    "# 손실 함수 및 최적화\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "torch.set_grad_enabled(True)\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    loss_sum = 0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss_sum:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 시각화\n",
    "weights = model.linear.weight.data\n",
    "weights = weights.view(10, 28, 28)\n",
    "figure, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(weights[i].cpu().numpy(), cmap='gray')\n",
    "    ax.set_title(f'Digit {i}')\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2. VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터셋\n",
    "dataset_train = load_dataset(\n",
    "    'cifar10',\n",
    "    split='train', # training dataset\n",
    "    verification_mode=VerificationMode.NO_CHECKS\n",
    ")\n",
    "\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 데이터셋\n",
    "dataset_valid = load_dataset(\n",
    "    'cifar10',\n",
    "    split='test',  # test set\n",
    "    verification_mode=VerificationMode.NO_CHECKS\n",
    ")\n",
    "\n",
    "dataset_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 개수\n",
    "num_classes = len(set(dataset_train['label']))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인\n",
    "plt.imshow(dataset_train[0]['img'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # 이미지를 32x32로 Resize\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = []\n",
    "\n",
    "for record in tqdm(dataset_train):\n",
    "    image = record['img']\n",
    "    label = record['label']\n",
    "\n",
    "    # gray to RGP (입력 형태를 동일하게)\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert(\"RGB\")\n",
    "        \n",
    "    # prepocessing\n",
    "    input_tensor = preprocess(image)\n",
    "    \n",
    "    inputs_train.append([input_tensor, label]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(inputs_train), inputs_train[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_valid = []\n",
    "\n",
    "for record in tqdm(dataset_valid):\n",
    "    image = record['img']\n",
    "    label = record['label']\n",
    "\n",
    "    # gray to RGP (입력 형태를 동일하게)\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert(\"RGB\")\n",
    "        \n",
    "    # prepocessing\n",
    "    input_tensor = preprocess(image)\n",
    "    \n",
    "    inputs_valid.append([input_tensor, label]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(inputs_valid), inputs_valid[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to dataloaders\n",
    "dloader_train = torch.utils.data.DataLoader(\n",
    "  \tinputs_train,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dloader_valid = torch.utils.data.DataLoader(\n",
    "  \tinputs_valid,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16 loading\n",
    "model = models.vgg16(pretrained=True)  # 학습된 파라미터로 모델 로딩\n",
    "# model = models.vgg16(pretrained=False)  # 랜덤 파라미터로 모델 로딩\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier linear 3 수정\n",
    "model.classifier[6] = nn.Sequential(\n",
    "                          nn.Linear(4096, 512),\n",
    "                          nn.ReLU(), \n",
    "                          nn.Dropout(0.5),\n",
    "                          nn.Linear(512, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model이 GPU를 사용하도록\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "# learning rate \n",
    "lr = 0.001\n",
    "# SGD optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() # train mode\n",
    "\n",
    "    # 학습\n",
    "    for i, (images, labels) in enumerate(tqdm(dloader_train)):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        # loss\n",
    "        loss = loss_func(outputs, labels)\n",
    "\n",
    "        # backward & optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 평가\n",
    "    with torch.no_grad():  # no gradient\n",
    "        model.eval() # eval mode\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_val_loss = []\n",
    "\n",
    "        for images, labels in dloader_valid:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # forward\n",
    "            outputs = model(images)\n",
    "            # total count\n",
    "            total += labels.size(0)\n",
    "            # predicted label\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            # calculate correct\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # calculate the loss\n",
    "            all_val_loss.append(loss_func(outputs, labels).item())\n",
    "        # calculate val-loss\n",
    "        val_loss = sum(all_val_loss) / len(all_val_loss)\n",
    "        # calculate val-accuracy\n",
    "        val_acc = 100 * (correct / total)\n",
    "    print(f\"Epoch: {epoch + 1} / {num_epochs}, Val-loss: {val_loss:.4f}, Val-ac: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
