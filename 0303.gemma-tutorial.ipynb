{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "402838bd-5b9a-434c-bc1c-f071a218cafb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 0. Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82b3250-28a1-4c8d-974d-dde7673c76b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForCausalLM,\n",
    "                          BitsAndBytesConfig,\n",
    "                          pipeline,\n",
    "                          TrainingArguments)\n",
    "from peft import (LoraConfig,\n",
    "                  PeftModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5458f231-f05e-481c-994f-f89e0d913c36",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. Gemma-2b-it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e622730f-473a-456a-8a70-e1467d8e39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론에 사용할 LLM\n",
    "MODEL_ID = 'google/gemma-1.1-2b-it'\n",
    "# hugging face access token을 복사하세요.\n",
    "HF_TOKEN = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706318c8-43b2-4c05-9540-9a1869a992db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare 4 bits quantize\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaa7dc5-c781-490c-a2e2-e0d73f0a5013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 4 bits model\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_ID,\n",
    "                                             device_map='auto',\n",
    "                                             quantization_config=quantization_config,\n",
    "                                             token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a794a19-20ab-4888-940e-cdd45a0bdf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID,\n",
    "                                          add_special_tokens=True,\n",
    "                                          token=HF_TOKEN)\n",
    "tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffa5fec-854d-4ebc-9c19-5abca8c2ba2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.1. Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5473efb0-da64-488b-a75e-ebcd57abd6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm 추론 pipeline\n",
    "# https://huggingface.co/docs/transformers/main_classes/pipelines\n",
    "pipe = pipeline(\"text-generation\",\n",
    "                model=model,\n",
    "                tokenizer=tokenizer,\n",
    "                max_new_tokens=512)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8491f2-7799-4634-88c2-063eacc8cf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"엄청나게 즐거운 시간이었습니다. 강추!!!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6034e771-24d9-49da-8fc5-fa8172c01a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"다음 문장은 영화리뷰입니다. 긍정 또는 부정으로 분류해주세요:\\n\\n{}\".format(doc)\n",
    "    }\n",
    "]\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages,\n",
    "                                            tokenize=False,\n",
    "                                            add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b0cab2-2181-48f3-86af-a3439d33c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gemma 기본 prompt 형식\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11bfcea-22dd-4ee7-808d-d66ba74d7de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline에 prompt를 입력해서 추론\n",
    "outputs = pipe(\n",
    "    prompt,\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    top_k=50,\n",
    "    top_p=0.95\n",
    ")\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81546b5-e93e-4d90-b74e-ce3d69e29906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 문장 출력\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e92e45-9f9e-4877-9a46-8ed81d73b056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트를 제외한 생성된 문장만 출력\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cf500e-7fb8-4094-a517-be4182c302b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.2. 연습문제\n",
    "- 아래 gen_prompt를 수정해서 질문에 답하는 챗봇을 만들어 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7acce0-3731-4f7f-a634-1562eb58ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_prompt(pipe, doc):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"다음 문장은 영화리뷰입니다. 긍정 또는 부정으로 분류해주세요:\\n\\n{}\".format(doc)\n",
    "        }\n",
    "    ]\n",
    "    prompt = pipe.tokenizer.apply_chat_template(messages,\n",
    "                                                tokenize=False,\n",
    "                                                add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a33e985-93b9-48ca-afab-f98d12f79f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_response(pipe, doc):\n",
    "    prompt = gen_prompt(pipe, doc)\n",
    "\n",
    "    outputs = pipe(\n",
    "        prompt,\n",
    "        do_sample=True,\n",
    "        temperature=0.2,\n",
    "        top_k=50,\n",
    "        top_p=0.95\n",
    "    )\n",
    "    return outputs[0][\"generated_text\"][len(prompt):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeccaf52-f0d5-4a0e-b6af-71e62f14eb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    doc = input('문장 > ')\n",
    "    doc = doc.strip()\n",
    "    if len(doc) == 0:\n",
    "        break\n",
    "    result = gen_response(pipe, doc)\n",
    "    print(f'감정 > {result}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94618012-89f3-4d01-9ac6-9b1917f2a284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
