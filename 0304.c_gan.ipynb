{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44524fb9-c42e-417b-9ce9-32104363e69f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 0. Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15789c2-04a4-4e9e-aa6f-471130273e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL\n",
    "from tqdm.auto import trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8551d3-51f9-4e5f-b601-348bea6730a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient False\n",
    "# Pytorch에서 동작을 확안하기 위해서 Gradient 계산을 하지 않도록 설정\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f989106-0ec3-4951-bfd8-b2715a7a18d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. C-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe876a-3d80-4477-9812-66eb197f86b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf7475-aa3d-41ec-91ea-fe791591188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = 10 # number of class\n",
    "d_latent = 100 # latent vector z dimension\n",
    "s_image = 28 * 28 # size of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81a46e3-3313-455c-97a1-11c462f53d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a94dde-afde-41b8-b8d1-97965fe17eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자 모델\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 조건 임베딩\n",
    "        self.embed = torch.nn.Embedding(n_class, n_class)\n",
    "        # 생성자 layers\n",
    "        self.layer_1 = Generator.FcBnRelu(d_latent + n_class, 128, normalize=False)\n",
    "        self.layer_2 = Generator.FcBnRelu(128, 256)\n",
    "        self.layer_3 = Generator.FcBnRelu(256, 512)\n",
    "        self.layer_4 = Generator.FcBnRelu(512, 1024)\n",
    "        self.layer_o = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1024, s_image),\n",
    "            torch.nn.Tanh()\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def FcBnRelu(d_in, d_out, normalize=True):\n",
    "        layers = [torch.nn.Linear(d_in, d_out)]\n",
    "        if normalize:\n",
    "            layers.append(torch.nn.BatchNorm1d(d_out, 0.8))\n",
    "        layers.append(torch.nn.LeakyReLU(0.2, inplace=True))\n",
    "        return torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, z, y):\n",
    "        # class를 벡터로 변경\n",
    "        y_hidden = self.embed(y)\n",
    "        # 두 벡터를 합쳐서 하나의 벡터로 변경\n",
    "        hidden = torch.cat([z, y_hidden], dim=-1)\n",
    "        # layer 실행\n",
    "        hidden = self.layer_1(hidden)\n",
    "        hidden = self.layer_2(hidden)\n",
    "        hidden = self.layer_3(hidden)\n",
    "        hidden = self.layer_4(hidden)\n",
    "        # output\n",
    "        logits = self.layer_o(hidden)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba02b680-4e99-433f-b45b-dc8bf6d1e493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판별자\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 조건 임베딩\n",
    "        self.embed = torch.nn.Embedding(n_class, n_class)\n",
    "\n",
    "        self.layer_1 = Discriminator.FcDoRelu(s_image + n_class, 512, dropout=0.0)\n",
    "        self.layer_2 = Discriminator.FcDoRelu(512, 512)\n",
    "        self.layer_3 = Discriminator.FcDoRelu(512, 512)\n",
    "        self.layer_o = torch.nn.Sequential(\n",
    "            torch.nn.Linear(512, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def FcDoRelu(d_in, d_out, dropout=0.4):\n",
    "        layers = [torch.nn.Linear(d_in, d_out)]\n",
    "        if dropout > 0:\n",
    "            layers.append(torch.nn.Dropout(dropout))\n",
    "        layers.append(torch.nn.LeakyReLU(0.2, inplace=True))\n",
    "        return torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, img, y):\n",
    "        # class를 벡터로 변경\n",
    "        y_hidden = self.embed(y)\n",
    "        # 두 벡터를 합쳐서 하나의 벡터로 변경\n",
    "        hidden = torch.cat([img, y_hidden], dim=-1)\n",
    "        # layer 실행\n",
    "        hidden = self.layer_1(hidden)\n",
    "        hidden = self.layer_2(hidden)\n",
    "        hidden = self.layer_3(hidden)\n",
    "        # output\n",
    "        logits = self.layer_o(hidden)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0184026d-267b-4182-89b4-924f0f821f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator 생성\n",
    "generator = Generator()\n",
    "generator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875c591c-fb7f-4652-bf06-13212d044687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator 생성\n",
    "discriminator = Discriminator()\n",
    "discriminator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ce2b2-dc96-44c9-835a-9df33fb3c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 함수\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "# optimizer\n",
    "optimG = torch.optim.Adam(generator.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "optimD = torch.optim.Adam(discriminator.parameters(), lr=1e-4, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385846a5-2875-4ef8-86a3-3248440cae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 100\n",
    "# 전체 step 수\n",
    "n_total_train = len(train_loader) * n_epoch\n",
    "n_total_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7276dbcb-3295-4a48-91e5-49385711504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습을 위해 gradinet 계산 활성\n",
    "torch.set_grad_enabled(True)\n",
    "p_bar = trange(n_total_train)\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_d_loss, train_g_loss = [], []\n",
    "    # train\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    for images, labels in train_loader:\n",
    "        # real y and images\n",
    "        real_img, real_y = images.to(device), labels.to(device)\n",
    "        n_batch = real_y.shape[0]\n",
    "        real_img = real_img.view(n_batch, -1)\n",
    "\n",
    "        # fake y and latent z\n",
    "        fake_y = torch.randint(0, 10, (n_batch, )).to(device)\n",
    "        z = torch.tensor(np.random.normal(0, 1, (n_batch, d_latent))).type(torch.float).to(device)\n",
    "\n",
    "        # real label & fake label\n",
    "        real_labels = torch.ones(n_batch).to(device)\n",
    "        fake_labels = torch.zeros(n_batch).to(device)\n",
    "\n",
    "        ##########################################################\n",
    "        # train discirminator\n",
    "        ##########################################################\n",
    "        optimD.zero_grad()\n",
    "\n",
    "        # loss for real images predict real\n",
    "        real_logits = discriminator(real_img, real_y)\n",
    "        d_real_loss = loss_fn(real_logits.view(-1), real_labels)\n",
    "\n",
    "        # loss for fake images predict fake\n",
    "        fake_img = generator(z, fake_y)\n",
    "        fake_logits = discriminator(fake_img.detach(), fake_y)\n",
    "        d_fake_loss = loss_fn(fake_logits.view(-1), fake_labels)\n",
    "\n",
    "        # loss\n",
    "        d_loss = (d_real_loss + d_fake_loss)\n",
    "        train_d_loss.append(d_loss.item())\n",
    "\n",
    "        # update\n",
    "        d_loss.backward()\n",
    "        optimD.step()\n",
    "\n",
    "        ##########################################################\n",
    "        # train generator\n",
    "        ##########################################################\n",
    "        optimG.zero_grad()\n",
    "\n",
    "        # loss for fake images predict real\n",
    "        fake_img = generator(z, fake_y)\n",
    "        fake_logits = discriminator(fake_img, fake_y)\n",
    "        g_loss = loss_fn(fake_logits.view(-1), real_labels)\n",
    "        train_g_loss.append(g_loss.item())\n",
    "\n",
    "        # update\n",
    "        g_loss.backward()\n",
    "        optimG.step()\n",
    "\n",
    "        # display progress\n",
    "        p_bar.set_description(f'train epoch: {epoch + 1:3d}, d_loss: {np.mean(train_d_loss):.4f}, g_loss: {np.mean(train_g_loss):.4f}')\n",
    "        p_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd8847-e87d-49d4-96a1-457d8dc8208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_generate(generator, y):\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        # 숫자별로 1개 이미지 생성을 위한 입력\n",
    "        fake_y = torch.tensor([y]).to(device)\n",
    "        z = torch.tensor(np.random.normal(0, 1, (1, d_latent))).type(torch.float).to(device)\n",
    "        # 이미지 생성\n",
    "        fake_img = generator(z, fake_y)\n",
    "        # numpy array로 변경\n",
    "        fake_img = fake_img.view(28, 28)\n",
    "        fake_img = fake_img.cpu().detach().numpy()\n",
    "    # de normalize\n",
    "    fake_img = (fake_img * 0.5) + 0.5\n",
    "    fake_img = fake_img * 255.\n",
    "    # concat all image\n",
    "    fake_img = fake_img.astype(np.ubyte)\n",
    "    display(PIL.Image.fromarray(fake_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29924c47-6235-43d3-b502-819a42db63d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    string = input('번호 (0 ~ 9) > ')\n",
    "    string = string.strip()\n",
    "    if len(string) == 0:\n",
    "        break\n",
    "    y = int(string)\n",
    "    if 0 <= y <= 9:\n",
    "        do_generate(generator, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaad996-33e4-46ae-ae51-84fb0ee89ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
